<!DOCTYPE HTML>
<html lang="zh-CN">


<head><meta name="generator" content="Hexo 3.9.0">
    <meta charset="utf-8">
    <meta name="keywords" content="kafka学习笔记">
    <meta name="description" content>
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>kafka学习笔记 | Tom Blog</title>
    <link rel="icon" type="image/png" href="/favicon.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">

    <script src="/libs/jquery/jquery.min.js"></script>

<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head>




<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Tom Blog</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>留言板</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Tom Blog</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			留言板
		</a>
          
        </li>
        
        
    </ul>
</div>


        </div>

        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/12.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">kafka学习笔记</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        padding: 35px 0 15px 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        padding-bottom: 30px;
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;

        position: absolute;
        right: 23.5vw;
        display: block;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                          <div class="article-tag">
                            <span class="chip bg-color">无标签</span>
                          </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/MQ/" class="post-category">
                                MQ
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2021-04-27
                </div>
                

                

                

                

                
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <h2 id="kafka笔记"><a href="#kafka笔记" class="headerlink" title="kafka笔记"></a>kafka笔记</h2><p>网站：<br><a href="https://www.cnblogs.com/qcloud1001/p/8984590.html" target="_blank" rel="noopener">https://www.cnblogs.com/qcloud1001/p/8984590.html</a></p>
<p><a href="https://www.cnblogs.com/lfs2640666960/p/11380298.html" target="_blank" rel="noopener">https://www.cnblogs.com/lfs2640666960/p/11380298.html</a></p>
<h3 id="一、为什么需要消息系统"><a href="#一、为什么需要消息系统" class="headerlink" title="一、为什么需要消息系统"></a>一、为什么需要消息系统</h3><p><strong>1.解耦：</strong><br>允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束。<br><strong>2.冗余：</strong><br>　　消息队列把数据进行持久化直到它们已经被完全处理，通过这一方式规避了数据丢失风险。许多消息队列所采用的”插入-获取-删除”范式中，在把一个消息从队列中删除之前，需要你的处理系统明确的指出该消息已经被处理完毕，从而确保你的数据被安全的保存直到你使用完毕。<br><strong>3.扩展性：</strong><br>　　因为消息队列解耦了你的处理过程，所以增大消息入队和处理的频率是很容易的，只要另外增加处理过程即可。<br><strong>4.灵活性 &amp; 峰值处理能力：</strong><br>　　在访问量剧增的情况下，应用仍然需要继续发挥作用，但是这样的突发流量并不常见。如果为以能处理这类峰值访问为标准来投入资源随时待命无疑是巨大的浪费。使用消息队列能够使关键组件顶住突发的访问压力，而不会因为突发的超负荷的请求而完全崩溃。<br><strong>5.可恢复性：</strong><br>　　系统的一部分组件失效时，不会影响到整个系统。消息队列降低了进程间的耦合度，所以即使一个处理消息的进程挂掉，加入队列中的消息仍然可以在系统恢复后被处理。<br><strong>6.顺序保证：</strong><br>　　在大多使用场景下，数据处理的顺序都很重要。大部分消息队列本来就是排序的，并且能保证数据会按照特定的顺序来处理。（Kafka 保证一个 Partition 内的消息的有序性）<br><strong>7.缓冲：</strong><br>　　有助于控制和优化数据流经过系统的速度，解决生产消息和消费消息的处理速度不一致的情况。<br><strong>8.异步通信：</strong><br>　　很多时候，用户不想也不需要立即处理消息。消息队列提供了异步处理机制，允许用户把一个消息放入队列，但并不立即处理它。想向队列中放入多少消息就放多少，然后在需要的时候再去处理它们。</p>
<h3 id="二、kafka-架构"><a href="#二、kafka-架构" class="headerlink" title="二、kafka 架构"></a>二、kafka 架构</h3><hr>
<p>Kafka架构</p>
<p>它的架构包括以下组件：</p>
<p>主题（Topic）：是特定类型的消息流。消息是字节的有效负载（Payload），话题是消息的分类名或种子（Feed）名。</p>
<p>生产者（Producer）：是能够发布消息到话题的任何对象。</p>
<p>服务代理（Broker）：已发布的消息保存在一组服务器中，它们被称为代理（Broker）或Kafka集群。</p>
<p>消费者（Consumer）：可以订阅一个或多个话题，并从Broker拉数据，从而消费这些已发布的消息。</p>
<h4 id="2-1-拓扑结构"><a href="#2-1-拓扑结构" class="headerlink" title="2.1 拓扑结构"></a>2.1 拓扑结构</h4><p>如下图：</p>
<p><img src="https://gitee.com/fly_tom/use/raw/master/ka1.png" alt="image"></p>
<p>图.1</p>
<h4 id="2-2-相关概念"><a href="#2-2-相关概念" class="headerlink" title="2.2 相关概念"></a>2.2 相关概念</h4><ul>
<li><p>KafkaConsumer和KafkaProducer不同，后者是线程安全的，因此我们鼓励用户在多个线程中共享一个KafkaProducer实例，这样通常都要比每个线程维护一个KafkaProducer实例效率要高。但对于KafkaConsumer而言，它不是线程安全的</p>
</li>
<li><p><strong>Topic</strong>：Topic在逻辑上可以被认为是一个queue。每条消费都必须指定它的topic，可以简单理解为必须指明把这条消息放进哪个queue里。</p>
<ul>
<li><strong>Partition</strong>：是物理概念上的分区，为了提供系统吞吐率，在物理上每个Topic会分成一个或多个Partition，每个Partition对应一个文件夹，通过partition实现了并行处理和水平扩展<ul>
<li>offset：每个partition都由一系列有序的、不可变的消息组成，这些消息被连续的追加到partition中。partition中的每个消息都有一个连续的序列号叫做offset,用于partition唯一标识一条消息.</li>
<li>Segment：<ul>
<li>partition物理上由多个segment组成，每个Segment存着message信息</li>
<li>一个Segment对应一个文件</li>
<li>Segment由一个个不可变记录组成</li>
<li>记录只会被append到Segment中，不会被单独修改或删除</li>
<li>清除过期日志时，直接删除一个或多个Segment</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<ul>
<li><p><strong>ISR</strong>：In-Sync Replicas 副本同步队列 (kafka副本 实现高可用)</p>
</li>
<li><p><strong>Producer</strong>：消息产生者，负责生产消息并发送到Kafka Broker</p>
</li>
<li><p><strong>Consumer</strong>：消息消费者，向kafka broker读取消息并处理的客户端。</p>
<ul>
<li><p>消费者就是消息的使用者，在消费者端也有几个名词需要区分一下。</p>
<blockquote>
<p>一般消息队列有两种模式的消费方式，分别是 队列模式（或者 点对点模式） 和 发布订阅模式。</p>
</blockquote>
<ul>
<li>队列模式：一对一，就是一个消息只能被一个消费者消费，不能重复消费。一般情况队列支持存在多个消费者，但是对于一个消息，只会有一个消费者可以消费它。</li>
<li>订阅模式：一对多，一个消息可能被多次消费，消息生产者将消息发布到Topic中，只要是订阅改Topic的消费者都可以消费。</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>Consumer Group</strong>：各个consumer（consumer 线程）可以组成一个组（Consumer group ），partition中的每个message只能被组（Consumer group ）中的一个consumer（consumer 线程）消费，如果一个message可以被多个consumer（consumer 线程）消费的话，那么这些consumer必须在不同的组。Kafka不支持一个partition中的message由两个或两个以上的同一个consumer group下的consumer thread来处理，除非再启动一个新的consumer group。所以如果想同时对一个topic做消费的话，启动多个consumer group就可以了，但是要注意的是，这里的多个consumer的消费都必须是顺序读取partition里面的message，新启动的consumer默认从partition队列最头端最新的地方开始阻塞的读message。</p>
</li>
<li><p><strong>Broker</strong>：消息中间件处理结点，一个Kafka节点就是一个broker，多个broker可以组成一个Kafka集群。</p>
<ul>
<li>Controller：中央控制器Control，负责管理分区和副本状态并执行管理着这些分区的重新分配。（里面涉及到partition leader 选举）</li>
</ul>
</li>
<li><p>Replication:每一个分区都有多个副本，副本的作用是做备胎。当主分区（Leader）故障的时候会选择一个备胎（Follower）上位，成为Leader。在kafka中默认副本的最大数量是10个，且副本的数量不能大于Broker的数量，follower和leader绝对是在不同的机器，同一机器对同一个分区也只可能存放一个副本（包括自己）。</p>
</li>
<li><p><strong>controller</strong>：kafka 集群中的其中一个服务器，用来进行 leader election 以及 各种 failover。</p>
</li>
<li><p>Zookeeper：kafka集群依赖zookeeper来保存集群的的元信息，来保证系统的可用性。</p>
</li>
</ul>
<h4 id="2-3-zookeeper-节点"><a href="#2-3-zookeeper-节点" class="headerlink" title="2.3 zookeeper 节点"></a>2.3 zookeeper 节点</h4><p>kafka 在 zookeeper 中的存储结构如下图所示：</p>
<p><img src="https://gitee.com/fly_tom/use/raw/master/ka2.png" alt="image"></p>
<h3 id="三、producer-发布消息"><a href="#三、producer-发布消息" class="headerlink" title="三、producer 发布消息"></a>三、producer 发布消息</h3><hr>
<h4 id="3-1-写入方式"><a href="#3-1-写入方式" class="headerlink" title="3.1 写入方式"></a>3.1 写入方式</h4><p>producer 采用 push 模式将消息发布到 broker，每条消息都被 append 到 patition 中，属于顺序写磁盘（顺序写磁盘效率比随机写内存要高，保障 kafka 吞吐率）。<br><img src="https://gitee.com/fly_tom/use/raw/master/ka8.png" alt="image"></p>
<blockquote>
<p>需要注意的一点是，消息写入leader后，follower是主动的去leader进行同步的！producer采用push模式将数据发布到broker，每条消息追加到分区中，顺序写入磁盘，所以保证同一分区内的数据是有序的</p>
</blockquote>
<h4 id="3-2-消息路由"><a href="#3-2-消息路由" class="headerlink" title="3.2 消息路由"></a>3.2 消息路由</h4><p>producer 发送消息到 broker 时，会根据分区算法选择将其存储到哪一个 partition。其路由机制为：</p>
<p>1. 指定了 patition，则直接使用；<br>2. 未指定 patition 但指定 key，通过对 key 的 value 进行hash 选出一个 patition<br>3. patition 和 key 都未指定，使用轮询选出一个 patition。</p>
<h4 id="3-3-写入流程"><a href="#3-3-写入流程" class="headerlink" title="3.3 写入流程"></a>3.3 写入流程</h4><p> producer 写入消息序列图如下所示：</p>
<p><img src="https://gitee.com/fly_tom/use/raw/master/ka3.png" alt="image"></p>
<p>图.3</p>
<p>流程说明：</p>
<p>1. producer 先从 zookeeper 的 “/brokers/…/state” 节点找到该 partition 的 leader<br>2. producer 将消息发送给该 leader<br>3. leader 将消息写入本地 log<br>4. followers 从 leader pull 消息，写入本地 log 后 leader 发送 ACK<br>5. leader 收到所有 ISR 中的 replica 的 ACK 后，增加 HW（high watermark，最后 commit 的 offset） 并向 producer 发送 ACK</p>
<h4 id="3-4-producer-delivery-guarantee"><a href="#3-4-producer-delivery-guarantee" class="headerlink" title="3.4 producer delivery guarantee"></a>3.4 producer delivery guarantee</h4><p> 一般情况下存在三种情况：</p>
<p>1. At most once 消息可能会丢，但绝不会重复传输<br>2. At least one 消息绝不会丢，但可能会重复传输<br>3. Exactly once 每条消息肯定会被传输一次且仅传输一次</p>
<p>当 producer 向 broker 发送消息时，一旦这条消息被 commit，由于 replication 的存在，它就不会丢。但是如果 producer 发送数据给 broker 后，遇到网络问题而造成通信中断，那 Producer 就无法判断该条消息是否已经 commit。虽然 Kafka 无法确定网络故障期间发生了什么，但是 producer 可以生成一种类似于主键的东西，发生故障时幂等性的重试多次，这样就做到了 Exactly once，但目前还并未实现。所以目前默认情况下一条消息从 producer 到 broker 是确保了 At least once，可通过设置 producer 异步发送实现At most once。</p>
<p>保证消息不丢失是一个消息队列中间件的基本保证，那producer在向kafka写入消息的时候，怎么保证消息不丢失呢？那就是通过ACK应答机制！在生产者向队列写入数据的时候可以设置参数来确定是否确认kafka接收到数据，这个参数可设置的值为0、1、all。</p>
<ul>
<li>0代表producer往集群发送数据不需要等到集群的返回，不确保消息发送成功。安全性最低但是效率最高。</li>
</ul>
<ul>
<li><p>1代表producer往集群发送数据只要leader应答就可以发送下一条，只确保leader发送成功。</p>
</li>
<li><p>all代表producer往集群发送数据需要所有的follower都完成从leader的同步才会发送下一条，确保leader发送成功和所有的副本都完成备份。安全性最高，但是效率最低。</p>
</li>
</ul>
<h3 id="四、broker-保存消息"><a href="#四、broker-保存消息" class="headerlink" title="四、broker 保存消息"></a>四、broker 保存消息</h3><hr>
<blockquote>
<p>　Producer将数据写入kafka后，集群就需要对数据进行保存了！kafka将数据保存在磁盘，可能在我们的一般的认知里，写入磁盘是比较耗时的操作，不适合这种高并发的组件。Kafka初始会单独开辟一块磁盘空间，顺序写入数据（效率比随机写入高）。</p>
</blockquote>
<h4 id="4-1-存储方式"><a href="#4-1-存储方式" class="headerlink" title="4.1 存储方式"></a>4.1 存储方式</h4><p>物理上把 topic 分成一个或多个 patition（对应 server.properties 中的 num.partitions=3 配置），每个 patition 物理上对应一个文件夹（该文件夹存储该 patition 的所有消息和索引文件），如下：</p>
<p><img src="https://gitee.com/fly_tom/use/raw/master/ka4.png" alt="image"></p>
<p>Partition在服务器上的表现形式就是一个一个的文件夹，每个partition的文件夹下面会有多组segment文件，每组segment文件又包含.index文件、.log文件、.timeindex文件（早期版本中没有）三个文件， log文件就实际是存储message的地方，而index和timeindex文件为索引文件，用于检索消息。</p>
<p><img src="https://gitee.com/fly_tom/use/raw/master/ka9.png" alt="image"></p>
<p>　如上图，这个partition有三组segment文件，每个log文件的大小是一样的，但是存储的message数量是不一定相等的（每条的message大小不一致）。文件的命名是以该segment最小offset来命名的，如000.index存储offset为0~368795的消息，kafka就是利用分段+索引的方式来解决查找效率的问题。</p>
<h4 id="4-2-存储策略"><a href="#4-2-存储策略" class="headerlink" title="4.2 存储策略"></a>4.2 存储策略</h4><p>无论消息是否被消费，kafka 都会保留所有消息。有两种策略可以删除旧数据：</p>
<p>1. 基于时间：log.retention.hours=168<br>2. 基于大小：log.retention.bytes=1073741824</p>
<p>需要注意的是，因为Kafka读取特定消息的时间复杂度为O(1)，即与文件大小无关，所以这里删除过期文件与提高 Kafka 性能无关。</p>
<h4 id="4-3-topic-创建与删除"><a href="#4-3-topic-创建与删除" class="headerlink" title="4.3 topic 创建与删除"></a>4.3 topic 创建与删除</h4><h5 id="4-3-1-创建-topic"><a href="#4-3-1-创建-topic" class="headerlink" title="4.3.1 创建 topic"></a>4.3.1 创建 topic</h5><p>创建 topic 的序列图如下所示：</p>
<p><img src="https://gitee.com/fly_tom/use/raw/master/ka5.png" alt="image"></p>
<p>图.5</p>
<p>流程说明：</p>
<p>1. controller 在 ZooKeeper 的 /brokers/topics 节点上注册 watcher，当 topic 被创建，则 controller 会通过 watch 得到该 topic 的 partition/replica 分配。<br>2. controller从 /brokers/ids 读取当前所有可用的 broker 列表，对于 set_p 中的每一个 partition：<br>    2.1 从分配给该 partition 的所有 replica（称为AR）中任选一个可用的 broker 作为新的 leader，并将AR设置为新的 ISR<br>    2.2 将新的 leader 和 ISR 写入 /brokers/topics/[topic]/partitions/[partition]/state<br>3. controller 通过 RPC 向相关的 broker 发送 LeaderAndISRRequest。</p>
<h5 id="4-3-2-删除-topic"><a href="#4-3-2-删除-topic" class="headerlink" title="4.3.2 删除 topic"></a>4.3.2 删除 topic</h5><p>删除 topic 的序列图如下所示：</p>
<p><img src="https://gitee.com/fly_tom/use/raw/master/ka6.png" alt="image"></p>
<p>图.6</p>
<p>流程说明：</p>
<p>1. controller 在 zooKeeper 的 /brokers/topics 节点上注册 watcher，当 topic 被删除，则 controller 会通过 watch 得到该 topic 的 partition/replica 分配。<br>2. 若 delete.topic.enable=false，结束；否则 controller 注册在 /admin/delete_topics 上的 watch 被 fire，controller 通过回调向对应的 broker 发送 StopReplicaRequest。</p>
<h3 id="五、kafka-HA"><a href="#五、kafka-HA" class="headerlink" title="五、kafka HA"></a>五、kafka HA</h3><hr>
<h4 id="5-1-replication"><a href="#5-1-replication" class="headerlink" title="5.1 replication"></a>5.1 replication</h4><p>如图.1所示，同一个 partition 可能会有多个 replica（对应 server.properties 配置中的 default.replication.factor=N）。没有 replica 的情况下，一旦 broker 宕机，其上所有 patition 的数据都不可被消费，同时 producer 也不能再将数据存于其上的 patition。引入replication 之后，同一个 partition 可能会有多个 replica，而这时需要在这些 replica 之间选出一个 leader，producer 和 consumer 只与这个 leader 交互，其它 replica 作为 follower 从 leader 中复制数据。</p>
<p>Kafka 分配 Replica 的算法如下：</p>
<p>1. 将所有 broker（假设共 n 个 broker）和待分配的 partition 排序<br>2. 将第 i 个 partition 分配到第（i mod n）个 broker 上<br>3. 将第 i 个 partition 的第 j 个 replica 分配到第（(i + j) mode n）个 broker上</p>
<h4 id="5-2-选举"><a href="#5-2-选举" class="headerlink" title="5.2 选举"></a>5.2 选举</h4><p>当 partition 对应的 leader 宕机时，需要从 follower 中选举出新 leader。在选举新leader时，一个基本的原则是，新的 leader 必须拥有旧 leader commit 过的所有消息。</p>
<p>kafka 在 zookeeper 中（/brokers/…/state）动态维护了一个 ISR（in-sync replicas），ISR 里面的所有 replica 都跟上了 leader，只有 ISR 里面的成员才能选为 leader。对于 f+1 个 replica，一个 partition 可以在容忍 f 个 replica 失效的情况下保证消息不丢失。</p>
<p>当所有 replica 都不工作时，有两种可行的方案：</p>
<p>1. 等待 ISR 中的任一个 replica 活过来，并选它作为 leader。可保障数据不丢失，但时间可能相对较长。<br>2. 选择第一个活过来的 replica（不一定是 ISR 成员）作为 leader。无法保障数据不丢失，但相对不可用时间较短。</p>
<p>kafka 0.8.* 使用第二种方式。</p>
<p>kafka 通过 Controller 来选举 leader，流程请参考5.3节。</p>
<h4 id="5-3-broker-failover"><a href="#5-3-broker-failover" class="headerlink" title="5.3 broker failover"></a>5.3 broker failover</h4><p>kafka broker failover 序列图如下所示：</p>
<p><img src="https://gitee.com/fly_tom/use/raw/master/ka7.png" alt="image"></p>
<p>图.7</p>
<p>流程说明： </p>
<p>1. controller 在 zookeeper 的 /brokers/ids/[brokerId] 节点注册 Watcher，当 broker 宕机时 zookeeper 会 fire watch<br>2. controller 从 /brokers/ids 节点读取可用broker<br>3. controller决定set_p，该集合包含宕机 broker 上的所有 partition<br>4. 对 set_p 中的每一个 partition<br>    4.1 从/brokers/topics/[topic]/partitions/[partition]/state 节点读取 ISR<br>    4.2 决定新 leader（如4.3节所描述）<br>    4.3 将新 leader、ISR、controller_epoch 和 leader_epoch 等信息写入 state 节点<br>5. 通过 RPC 向相关 broker 发送 leaderAndISRRequest 命令</p>
<h4 id="5-4-controller-failover"><a href="#5-4-controller-failover" class="headerlink" title="5.4 controller failover"></a>5.4 controller failover</h4><p> 当 controller 宕机时会触发 controller failover。每个 broker 都会在 zookeeper 的 “/controller” 节点注册 watcher，当 controller 宕机时 zookeeper 中的临时节点消失，所有存活的 broker 收到 fire 的通知，每个 broker 都尝试创建新的 controller path，只有一个竞选成功并当选为 controller。</p>
<p>当新的 controller 当选时，会触发 KafkaController.onControllerFailover 方法，在该方法中完成如下操作：</p>
<p>1. 读取并增加 Controller Epoch。<br>2. 在 reassignedPartitions Patch(/admin/reassign_partitions) 上注册 watcher。<br>3. 在 preferredReplicaElection Path(/admin/preferred_replica_election) 上注册 watcher。<br>4. 通过 partitionStateMachine 在 broker Topics Patch(/brokers/topics) 上注册 watcher。<br>5. 若 delete.topic.enable=true（默认值是 false），则 partitionStateMachine 在 Delete Topic Patch(/admin/delete_topics) 上注册 watcher。<br>6. 通过 replicaStateMachine在 Broker Ids Patch(/brokers/ids)上注册Watch。<br>7. 初始化 ControllerContext 对象，设置当前所有 topic，“活”着的 broker 列表，所有 partition 的 leader 及 ISR等。<br>8. 启动 replicaStateMachine 和 partitionStateMachine。<br>9. 将 brokerState 状态设置为 RunningAsController。<br>10. 将每个 partition 的 Leadership 信息发送给所有“活”着的 broker。<br>11. 若 auto.leader.rebalance.enable=true（默认值是true），则启动 partition-rebalance 线程。<br>12. 若 delete.topic.enable=true 且Delete Topic Patch(/admin/delete_topics)中有值，则删除相应的Topic。</p>
<h3 id="六-consumer-消费消息"><a href="#六-consumer-消费消息" class="headerlink" title="六. consumer 消费消息"></a>六. consumer 消费消息</h3><hr>
<h4 id="6-2-consumer-group"><a href="#6-2-consumer-group" class="headerlink" title="6.2 consumer group"></a>6.2 consumer group</h4><p>如 2.2 节所说， kafka 的分配单位是 patition。每个 consumer 都属于一个 group，一个 partition 只能被同一个 group 内的一个 consumer 所消费（也就保障了一个消息只能被 group 内的一个 consuemr 所消费），但是多个 group 可以同时消费这个 partition。<br><strong>所以在实际的应用中，建议消费者组的consumer的数量与partition的数量一致！</strong></p>
<p>kafka 的设计目标之一就是同时实现离线处理和实时处理，根据这一特性，可以使用 spark/Storm 这些实时处理系统对消息在线处理，同时使用 Hadoop 批处理系统进行离线处理，还可以将数据备份到另一个数据中心，只需要保证这三者属于不同的 consumer group。如下图所示：</p>
<p><img src="https://gitee.com/fly_tom/use/raw/master/ka9.jpg" alt="image"></p>
<h4 id="6-3-消费方式"><a href="#6-3-消费方式" class="headerlink" title="6.3 消费方式"></a>6.3 消费方式</h4><hr>
<p>consumer 采用 pull 模式从 broker 中读取数据。</p>
<p>push 模式很难适应消费速率不同的消费者，因为消息发送速率是由 broker 决定的。它的目标是尽可能以最快速度传递消息，但是这样很容易造成 consumer 来不及处理消息，典型的表现就是拒绝服务以及网络拥塞。而 pull 模式则可以根据 consumer 的消费能力以适当的速率消费消息。</p>
<p>对于 Kafka 而言，pull 模式更合适，它可简化 broker 的设计，consumer 可自主控制消费消息的速率，同时 consumer 可以自己控制消费方式——即可批量消费也可逐条消费，同时还能选择不同的提交方式从而实现不同的传输语义。</p>
<h4 id="6-4-consumer-delivery-guarantee"><a href="#6-4-consumer-delivery-guarantee" class="headerlink" title="6.4 consumer delivery guarantee"></a>6.4 consumer delivery guarantee</h4><p>如果将 consumer 设置为 autocommit，consumer 一旦读到数据立即自动 commit。如果只讨论这一读取消息的过程，那 Kafka 确保了 Exactly once。</p>
<p>但实际使用中应用程序并非在 consumer 读取完数据就结束了，而是要进行进一步处理，而数据处理与 commit 的顺序在很大程度上决定了consumer delivery guarantee：</p>
<p><strong>1.读完消息先 commit 再处理消息。</strong><br>    这种模式下，如果 consumer 在 commit 后还没来得及处理消息就 crash 了，下次重新开始工作后就无法读到刚刚已提交而未处理的消息，这就对应于 At most once  </p>
<p><strong>2.读完消息先处理再 commit。</strong><br>    这种模式下，如果在处理完消息之后 commit 之前 consumer crash 了，下次重新开始工作时还会处理刚刚未 commit 的消息，实际上该消息已经被处理过了。这就对应于 At least once。  </p>
<p><strong>3.如果一定要做到 Exactly once，就需要协调 offset 和实际操作的输出。</strong><br>    精典的做法是引入两阶段提交。如果能让 offset 和操作输入存在同一个地方，会更简洁和通用。这种方式可能更好，因为许多输出系统可能不支持两阶段提交。比如，consumer 拿到数据后可能把数据放到 HDFS，如果把最新的 offset 和数据本身一起写到 HDFS，那就可以保证数据的输出和 offset 的更新要么都完成，要么都不完成，间接实现 Exactly once。（目前就 high-level API而言，offset 是存于Zookeeper 中的，无法存于HDFS，而SimpleConsuemr API的 offset 是由自己去维护的，可以将之存于 HDFS 中）</p>
<p>总之，Kafka 默认保证 At least once，并且允许通过设置 producer 异步提交来实现 At most once（见文章《kafka consumer防止数据丢失》）。而 Exactly once 要求与外部存储系统协作，幸运的是 kafka 提供的 offset 可以非常直接非常容易得使用这种方式。</p>
<p>更多关于 kafka 传输语义的信息请参考《Message Delivery Semantics》。</p>
<h4 id="6-5-consumer-rebalance（重新平衡）"><a href="#6-5-consumer-rebalance（重新平衡）" class="headerlink" title="6.5 consumer rebalance（重新平衡）"></a>6.5 consumer rebalance（重新平衡）</h4><p>当有 consumer 加入或退出、以及 partition 的改变（如 broker 加入或退出）时会触发 rebalance。consumer rebalance算法如下：</p>
<p>1. 将目标 topic 下的所有 partirtion 排序，存于PT<br>2. 对某 consumer group 下所有 consumer 排序，存于 CG，第 i 个consumer 记为 Ci<br>3. N=size(PT)/size(CG)，向上取整<br>4. 解除 Ci 对原来分配的 partition 的消费权（i从0开始）<br>5. 将第i*N到（i+1）*N-1个 partition 分配给 Ci</p>
<p>在 0.8.*版本，每个 consumer 都只负责调整自己所消费的 partition，为了保证整个consumer group 的一致性，当一个 consumer 触发了 rebalance 时，该 consumer group 内的其它所有其它 consumer 也应该同时触发 rebalance。这会导致以下几个问题：</p>
<p><strong>1.Herd effect</strong><br>　　任何 broker 或者 consumer 的增减都会触发所有的 consumer 的 rebalance<br><strong>2.Split Brain</strong><br>　　每个 consumer 分别单独通过 zookeeper 判断哪些 broker 和 consumer 宕机了，那么不同 consumer 在同一时刻从 zookeeper 看到的 view 就可能不一样，这是由 zookeeper 的特性决定的，这就会造成不正确的 reblance 尝试。<br><strong>3. 调整结果不可控</strong><br>　　所有的 consumer 都并不知道其它 consumer 的 rebalance 是否成功，这可能会导致 kafka 工作在一个不正确的状态。</p>
<p>基于以上问题，kafka 设计者考虑在0.9.*版本开始使用中心 coordinator 来控制 consumer rebalance，然后又从简便性和验证要求两方面考虑，计划在 consumer 客户端实现分配方案。（见文章《Kafka Detailed Consumer Coordinator Design》和《Kafka Client-side Assignment Proposal》），此处不再赘述。</p>
<h3 id="七、注意事项"><a href="#七、注意事项" class="headerlink" title="七、注意事项"></a>七、注意事项</h3><hr>
<h4 id="7-1-producer-无法发送消息的问题"><a href="#7-1-producer-无法发送消息的问题" class="headerlink" title="7.1 producer 无法发送消息的问题"></a>7.1 producer 无法发送消息的问题</h4><p>最开始在本机搭建了kafka伪集群，本地 producer 客户端成功发布消息至 broker。随后在服务器上搭建了 kafka 集群，在本机连接该集群，producer 却无法发布消息到 broker（奇怪也没有抛错）。最开始怀疑是 iptables 没开放，于是开放端口，结果还不行（又开始是代码问题、版本问题等等，倒腾了很久）。最后没办法，一项一项查看 server.properties 配置，发现以下两个配置：</p>
<pre><code>\# The address the socket server listens on. It will get the value returned from   
\# java.net.InetAddress.getCanonicalHostName() if not configured.  
\#   FORMAT:  
\#     listeners = security\_protocol://host\_name:port  
\#   EXAMPLE:  
\#     listeners = PLAINTEXT://your.host.name:9092  
listeners=PLAINTEXT://:9092

　# Hostname and port the broker will advertise to producers and consumers. If not set,   
　# it uses the value for "listeners" if configured. Otherwise, it will use the value  
　# returned from java.net.InetAddress.getCanonicalHostName().  
　#advertised.listeners=PLAINTEXT://your.host.name:9092</code></pre><p>以上说的就是 advertised.listeners 是 broker 给 producer 和 consumer 连接使用的，如果没有设置，就使用 listeners，而如果 host_name 没有设置的话，就使用 java.net.InetAddress.getCanonicalHostName() 方法返回的主机名。</p>
<p>修改方法：</p>
<p>1. listeners=PLAINTEXT://121.10.26.XXX:9092<br>2. advertised.listeners=PLAINTEXT://121.10.26.XXX:9092</p>
<p>修改后重启服务，正常工作。</p>
<h2 id="Kafka常见面试题"><a href="#Kafka常见面试题" class="headerlink" title="Kafka常见面试题"></a>Kafka常见面试题</h2><h3 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h3><p><strong>1 什么是kafka</strong></p>
<blockquote>
<p>Kafka是分布式发布-订阅消息系统，它最初是由LinkedIn公司开发的，之后成为Apache项目的一部分，Kafka是一个分布式，可划分的，冗余备份的持久性的日志服务，它主要用于处理流式数据。</p>
</blockquote>
<p><strong>2 为什么要使用 kafka，为什么要使用消息队列</strong></p>
<blockquote>
<p>缓冲和削峰：上游数据时有突发流量，下游可能扛不住，或者下游没有足够多的机器来保证冗余，kafka在中间可以起到一个缓冲的作用，把消息暂存在kafka中，下游服务就可以按照自己的节奏进行慢慢处理。</p>
<p>解耦和扩展性：项目开始的时候，并不能确定具体需求。消息队列可以作为一个接口层，解耦重要的业务流程。只需要遵守约定，针对数据编程即可获取扩展能力。</p>
<p>冗余：可以采用一对多的方式，一个生产者发布消息，可以被多个订阅topic的服务消费到，供多个毫无关联的业务使用。</p>
<p>健壮性：消息队列可以堆积请求，所以消费端业务即使短时间死掉，也不会影响主要业务的正常进行。</p>
<p>异步通信：很多时候，用户不想也不需要立即处理消息。消息队列提供了异步处理机制，允许用户把一个消息放入队列，但并不立即处理它。想向队列中放入多少消息就放多少，然后在需要的时候再去处理它们。</p>
</blockquote>
<p><strong>3.Kafka中的ISR、AR又代表什么？ISR的伸缩又指什么</strong></p>
<blockquote>
<p>ISR:In-Sync Replicas 副本同步队列<br>AR:Assigned Replicas 所有副本<br>ISR是由leader维护，follower从leader同步数据有一些延迟（包括延迟时间replica.lag.time.max.ms和延迟条数replica.lag.max.messages两个维度, 当前最新的版本0.10.x中只支持replica.lag.time.max.ms这个维度），任意一个超过阈值都会把follower剔除出ISR, 存入OSR（Outof-Sync Replicas）列表，新加入的follower也会先存放在OSR中。AR=ISR+OSR。</p>
</blockquote>
<p><strong>4.kafka中的broker 是干什么的</strong></p>
<blockquote>
<p>broker 是消息的代理，Producers往Brokers里面的指定Topic中写消息，Consumers从Brokers里面拉取指定Topic的消息，然后进行业务处理，broker在中间起到一个代理保存消息的中转站。</p>
</blockquote>
<p><strong>5.kafka中的 zookeeper 起到什么作用，可以不用zookeeper么</strong></p>
<blockquote>
<p>zookeeper 是一个分布式的协调组件，早期版本的kafka用zk做meta信息存储，consumer的消费状态，group的管理以及 offset的值。考虑到zk本身的一些因素以及整个架构较大概率存在单点问题，新版本中逐渐弱化了zookeeper的作用。新的consumer使用了kafka内部的group coordination协议，也减少了对zookeeper的依赖，</p>
<p>但是broker依然依赖于ZK，zookeeper 在kafka中还用来选举controller 和 检测broker是否存活等等。</p>
</blockquote>
<p><strong>6.kafka follower如何与leader同步数据</strong></p>
<blockquote>
<p>Kafka的复制机制既不是完全的同步复制，也不是单纯的异步复制。完全同步复制要求All Alive Follower都复制完，这条消息才会被认为commit，这种复制方式极大的影响了吞吐率。而异步复制方式下，Follower异步的从Leader复制数据，数据只要被Leader写入log就被认为已经commit，这种情况下，如果leader挂掉，会丢失数据，kafka使用ISR的方式很好的均衡了确保数据不丢失以及吞吐率。Follower可以批量的从Leader复制数据，而且Leader充分利用磁盘顺序读以及send file(zero copy)机制，这样极大的提高复制性能，内部批量写磁盘，大幅减少了Follower与Leader的消息量差。</p>
</blockquote>
<p><strong>7.什么情况下一个 broker 会从 isr中踢出去</strong></p>
<blockquote>
<p>leader会维护一个与其基本保持同步的Replica列表，该列表称为ISR(in-sync Replica)，每个Partition都会有一个ISR，而且是由leader动态维护 ，如果一个follower比一个leader落后太多，或者超过一定时间未发起数据复制请求，则leader将其重ISR中移除 。</p>
</blockquote>
<p><strong>8.kafka 为什么那么快</strong></p>
<blockquote>
<ul>
<li><p>Cache Filesystem Cache PageCache缓存</p>
</li>
<li><p>顺序写 由于现代的操作系统提供了预读和写技术，磁盘的顺序写大多数情况下比随机写内存还要快。</p>
</li>
<li><p>Zero-copy 零拷技术减少拷贝次数</p>
</li>
<li><p>Batching of Messages 批量量处理。合并小的请求，然后以流的方式进行交互，直顶网络上限。</p>
</li>
<li><p>Pull 拉模式 使用拉模式进行消息的获取消费，与消费端处理能力相符。</p>
</li>
</ul>
</blockquote>
<p><strong>9.kafka producer如何优化打入速度</strong></p>
<blockquote>
<ul>
<li><p>增加线程</p>
</li>
<li><p>提高 batch.size</p>
</li>
<li><p>增加更多 producer 实例</p>
</li>
<li><p>增加 partition 数</p>
</li>
<li><p>设置 acks=-1 时，如果延迟增大：可以增大 num.replica.fetchers（follower 同步数据的线程数）来调解；</p>
</li>
<li><p>跨数据中心的传输：增加 socket 缓冲区设置以及 OS tcp 缓冲区设置。</p>
</li>
</ul>
</blockquote>
<p><strong>10.kafka producer 打数据，ack 为 0， 1， -1 的时候代表啥， 设置 -1 的时候，什么情况下，leader 会认为一条消息 commit了</strong></p>
<blockquote>
<ol>
<li>1（默认） 数据发送到Kafka后，经过leader成功接收消息的的确认，就算是发送成功了。在这种情况下，如果leader宕机了，则会丢失数据。</li>
<li>0 生产者将数据发送出去就不管了，不去等待任何返回。这种情况下数据传输效率最高，但是数据可靠性确是最低的。</li>
<li>-1 producer需要等待ISR中的所有follower都确认接收到数据后才算一次发送完成，可靠性最高。当ISR中所有Replica都向Leader发送ACK时，leader才commit，这时候producer才能认为一个请求中的消息都commit了。</li>
</ol>
</blockquote>
<p><strong>11.kafka unclean 配置代表啥，会对 spark streaming 消费有什么影响</strong></p>
<blockquote>
<p>unclean.leader.election.enable 为true的话，意味着非ISR集合的broker 也可以参与选举，这样有可能就会丢数据，spark streaming在消费过程中拿到的 end offset 会突然变小，导致 spark streaming job挂掉。如果unclean.leader.election.enable参数设置为true，就有可能发生数据丢失和数据不一致的情况，Kafka的可靠性就会降低；而如果unclean.leader.election.enable参数设置为false，Kafka的可用性就会降低。</p>
</blockquote>
<p><strong>12.如果leader crash时，ISR为空怎么办</strong></p>
<blockquote>
<p>kafka在Broker端提供了一个配置参数：unclean.leader.election,这个参数有两个值：<br>true（默认）：允许不同步副本成为leader，由于不同步副本的消息较为滞后，此时成为leader，可能会出现消息不一致的情况。<br>false：不允许不同步副本成为leader，此时如果发生ISR列表为空，会一直等待旧leader恢复，降低了可用性。</p>
</blockquote>
<p><strong>13.kafka的message格式是什么样的</strong></p>
<blockquote>
<p>一个Kafka的Message由一个固定长度的header和一个变长的消息体body组成</p>
<p>header部分由一个字节的magic(文件格式)和四个字节的CRC32(用于判断body消息体是否正常)构成。</p>
<p>当magic的值为1的时候，会在magic和crc32之间多一个字节的数据：attributes(保存一些相关属性，</p>
<p>比如是否压缩、压缩格式等等);如果magic的值为0，那么不存在attributes属性</p>
<p>body是由N个字节构成的一个消息体，包含了具体的key/value消息</p>
</blockquote>
<p><strong>14.kafka中consumer group 是什么概念</strong></p>
<blockquote>
<p>同样是逻辑上的概念，是Kafka实现单播和广播两种消息模型的手段。同一个topic的数据，会广播给不同的group；同一个group中的worker，只有一个worker能拿到这个数据。换句话说，对于同一个topic，每个group都可以拿到同样的所有数据，但是数据进入group后只能被其中的一个worker消费。group内的worker可以使用多线程或多进程来实现，也可以将进程分散在多台机器上，worker的数量通常不超过partition的数量，且二者最好保持整数倍关系，因为Kafka在设计时假定了一个partition只能被一个worker消费（同一group内）。</p>
</blockquote>
<p><strong>15.Kafka中的消息是否会丢失和重复消费？</strong></p>
<blockquote>
<p>要确定Kafka的消息是否丢失或重复，从两个方面分析入手：消息发送和消息消费。</p>
<p><strong>1、消息发送</strong></p>
<p>Kafka消息发送有两种方式：同步（sync）和异步（async），默认是同步方式，可通过producer.type属性进行配置。Kafka通过配置request.required.acks属性来确认消息的生产：</p>
<ol>
<li><em>0—表示不进行消息接收是否成功的确认；</em></li>
<li><em>1—表示当Leader接收成功时确认；</em></li>
<li><em>-1—表示Leader和Follower都接收成功时确认；</em></li>
</ol>
<p>综上所述，有6种消息生产的情况，下面分情况来分析消息丢失的场景：</p>
<p>（1）acks=0，不和Kafka集群进行消息接收确认，则当网络异常、缓冲区满了等情况时，<strong>消息可能丢失</strong>；</p>
<p>（2）acks=1、同步模式下，只有Leader确认接收成功后但挂掉了，副本没有同步，<strong>数据可能丢失</strong>；</p>
<p><strong>2、消息消费</strong></p>
<p>Kafka消息消费有两个consumer接口，Low-level API和High-level API：</p>
<ol>
<li><p>Low-level API：消费者自己维护offset等值，可以实现对Kafka的完全控制；</p>
</li>
<li><p>High-level API：封装了对parition和offset的管理，使用简单；</p>
</li>
</ol>
<p>如果使用高级接口High-level API，可能存在一个问题就是当消息消费者从集群中把消息取出来、并提交了新的消息offset值后，还没来得及消费就挂掉了，那么下次再消费时之前没消费成功的消息就“_诡异_”的消失了；</p>
<p><strong>解决办法</strong>：</p>
<p>针对消息丢失：同步模式下，确认机制设置为-1，即让消息写入Leader和Follower之后再确认消息发送成功；异步模式下，为防止缓冲区满，可以在配置文件设置不限制阻塞超时时间，当缓冲区满时让生产者一直处于阻塞状态；</p>
<p>针对消息重复：将消息的唯一标识保存到外部介质中，每次消费时判断是否处理过即可。</p>
<p>消息重复消费及解决参考：<a href="https://www.javazhiyin.com/22910.html" target="_blank" rel="noopener">https://www.javazhiyin.com/22910.html</a></p>
</blockquote>
<p><strong>16.为什么Kafka不支持读写分离？</strong></p>
<blockquote>
<p>在 Kafka 中，生产者写入消息、消费者读取消息的操作都是与 leader 副本进行交互的，从 而实现的是一种<strong>主写主读</strong>的生产消费模型。</p>
<p>Kafka 并不支持主写从读，因为主写从读有 2 个很明 显的缺点:</p>
<ul>
<li><p>(1)<strong>数据一致性问题</strong>。数据从主节点转到从节点必然会有一个延时的时间窗口，这个时间 窗口会导致主从节点之间的数据不一致。某一时刻，在主节点和从节点中 A 数据的值都为 X， 之后将主节点中 A 的值修改为 Y，那么在这个变更通知到从节点之前，应用读取从节点中的 A 数据的值并不为最新的 Y，由此便产生了数据不一致的问题。</p>
</li>
<li><p>(2)<strong>延时问题</strong>。类似 Redis 这种组件，数据从写入主节点到同步至从节点中的过程需要经 历网络→主节点内存→网络→从节点内存这几个阶段，整个过程会耗费一定的时间。而在 Kafka 中，主从同步会比 Redis 更加耗时，它需要经历网络→主节点内存→主节点磁盘→网络→从节 点内存→从节点磁盘这几个阶段。对延时敏感的应用而言，主写从读的功能并不太适用。</p>
</li>
</ul>
</blockquote>
<p><strong>17.Kafka中是怎么体现消息顺序性的？</strong></p>
<blockquote>
<p>kafka每个partition中的消息在写入时都是有序的，消费时，每个partition只能被每一个group中的一个消费者消费，保证了消费时也是有序的。<br>整个topic不保证有序。如果为了保证topic整个有序，那么将partition调整为1.</p>
</blockquote>
<p><strong>18.消费者提交消费位移时提交的是当前消费到的最新消息的offset还是offset+1?</strong></p>
<blockquote>
<p>offset+1</p>
</blockquote>
<p><strong>19.kafka如何实现延迟队列？</strong></p>
<blockquote>
<p>Kafka并没有使用JDK自带的Timer或者DelayQueue来实现延迟的功能，而是<strong>基于时间轮自定义了一个用于实现延迟功能的定时器（SystemTimer）</strong>。JDK的Timer和DelayQueue插入和删除操作的平均时间复杂度为O(nlog(n))，并不能满足Kafka的高性能要求，而基于时间轮可以将插入和删除操作的时间复杂度都降为<strong>O(1)</strong>。时间轮的应用并非Kafka独有，其应用场景还有很多，在Netty、Akka、Quartz、Zookeeper等组件中都存在时间轮的踪影。</p>
<p>底层使用数组实现，数组中的每个元素可以存放一个TimerTaskList对象。TimerTaskList是一个环形双向链表，在其中的链表项TimerTaskEntry中封装了真正的定时任务TimerTask.</p>
<p>Kafka中到底是怎么推进时间的呢？Kafka中的定时器借助了JDK中的DelayQueue来协助推进时间轮。具体做法是对于每个使用到的TimerTaskList都会加入到DelayQueue中。<strong>Kafka中的TimingWheel专门用来执行插入和删除TimerTaskEntry的操作，而DelayQueue专门负责时间推进的任务</strong>。再试想一下，DelayQueue中的第一个超时任务列表的expiration为200ms，第二个超时任务为840ms，这里获取DelayQueue的队头只需要O(1)的时间复杂度。如果采用每秒定时推进，那么获取到第一个超时的任务列表时执行的200次推进中有199次属于“空推进”，而获取到第二个超时任务时有需要执行639次“空推进”，这样会无故空耗机器的性能资源，这里采用DelayQueue来辅助以少量空间换时间，从而做到了“精准推进”。Kafka中的定时器真可谓是“知人善用”，用TimingWheel做最擅长的任务添加和删除操作，而用DelayQueue做最擅长的时间推进工作，相辅相成。</p>
<p>参考：<a href="https://blog.csdn.net/u013256816/article/details/80697456" target="_blank" rel="noopener">https://blog.csdn.net/u013256816/article/details/80697456</a></p>
</blockquote>
<p><strong>20.Kafka中的事务是怎么实现的？</strong></p>
<blockquote>
<p>参考：<a href="https://blog.csdn.net/u013256816/article/details/89135417" target="_blank" rel="noopener">https://blog.csdn.net/u013256816/article/details/89135417</a></p>
</blockquote>
<p><strong>21</strong>.<strong>Kafka中有那些地方需要选举？这些地方的选举策略又有哪些？</strong></p>
<blockquote>
<p><strong><a href="https://blog.csdn.net/yanshu2012/article/details/54894629" target="_blank" rel="noopener">https://blog.csdn.net/yanshu2012/article/details/54894629</a></strong></p>
</blockquote>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>
                
            </div>
            <hr/>

            



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            <span class="chip bg-color">无标签</span>
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    
        <link rel="stylesheet" href="/libs/gitalk/gitalk.css">
<link rel="stylesheet" href="/css/my-gitalk.css">

<div class="card gitalk-card" data-aos="fade-up">
    <div class="comment_headling" style="font-size: 20px; font-weight: 700; position: relative; padding-left: 20px; top: 15px; padding-bottom: 5px;">
        <i class="fas fa-comments fa-fw" aria-hidden="true"></i>
        <span>评论</span>
    </div>
    <div id="gitalk-container" class="card-content"></div>
</div>

<script src="/libs/gitalk/gitalk.min.js"></script>
<script>
    let gitalk = new Gitalk({
        clientID: '33e35f8a39d17339ae45',
        clientSecret: 'c2daf8c102c345db91ff32aa45b2a692c7bdee25',
        repo: 'Fly_tom.github.io',
        owner: 'Flyiyu',
        admin: "Flyiyu",
        id: '2021-04-27T22-56-26',
        distractionFreeMode: false  // Facebook-like distraction free mode
    });

    gitalk.render('gitalk-container');
</script>

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2021/04/27/2019-06-16-kafka-pei-zhi-xin-xi/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/13.jpg" class="responsive-img" alt="kafka配置信息">
                        
                        <span class="card-title">kafka配置信息</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2021-04-27
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/MQ/" class="post-category">
                                    MQ
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/kafka/">
                        <span class="chip bg-color">kafka</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2021/04/27/2019-05-12-rabbitmq/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/10.jpg" class="responsive-img" alt="RabbitMQ笔记">
                        
                        <span class="card-title">RabbitMQ笔记</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2021-04-27
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/MQ/" class="post-category">
                                    MQ
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/RabbitMQ/">
                        <span class="chip bg-color">RabbitMQ</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>




    <footer class="page-footer bg-color">
    
    <div class="container row center-align" style="margin-bottom: 0px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2019-2021</span>
            
            <span id="year">2019</span>
            <a href="/about" target="_blank">FlyTom</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
            
            
            
            
            <br>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link ">














</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    

    

    

	
    

    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
