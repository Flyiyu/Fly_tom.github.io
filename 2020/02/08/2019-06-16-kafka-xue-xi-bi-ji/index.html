<!DOCTYPE HTML>
<html lang="zh-CN">


<head><meta name="generator" content="Hexo 3.9.0">
    <meta charset="utf-8">
    <meta name="keywords" content="kafka学习笔记, Tom Blog">
    <meta name="description" content="kafka学习笔记：知识点整理一、为什么需要消息系统1.解耦：允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束。2.冗余：　　消息队列把数据进行持久化直到它们已经被完全处理，通过这一方式规避了数据丢失风险。许多消息队列所">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <title>kafka学习笔记 | Tom Blog</title>
    <link rel="icon" type="image/png" href="/favicon.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">

    <script src="/libs/jquery/jquery-2.2.0.min.js"></script>
    
<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper head-container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Tom Blog</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>留言板</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>

<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Tom Blog</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			Contact
		</a>
          
        </li>
        
        
    </ul>
</div>


        </div>

        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/12.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <div class="description center-align post-title">
                        kafka学习笔记
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        margin: 35px 0 15px 0;
        padding-left: 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #toc-content .is-active-link::before {
        background-color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/kafka/">
                                <span class="chip bg-color">kafka</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/kafka/" class="post-category">
                                kafka
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2020-02-08
                </div>

                
                    
                    <div class="info-break-policy">
                        <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                        5.8k
                    </div>
                    

                    
                    <div class="info-break-policy">
                        <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                        22 分
                    </div>
                    
                
				
				
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">
        <div class="card-content article-card-content">
            <div id="articleContent">
                <h2 id="kafka学习笔记：知识点整理"><a href="#kafka学习笔记：知识点整理" class="headerlink" title="kafka学习笔记：知识点整理"></a>kafka学习笔记：知识点整理</h2><h2 id="一、为什么需要消息系统"><a href="#一、为什么需要消息系统" class="headerlink" title="一、为什么需要消息系统"></a><strong>一、为什么需要消息系统</strong></h2><p><strong>1.解耦：</strong><br>允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束。<br><strong>2.冗余：</strong><br>　　消息队列把数据进行持久化直到它们已经被完全处理，通过这一方式规避了数据丢失风险。许多消息队列所采用的”插入-获取-删除”范式中，在把一个消息从队列中删除之前，需要你的处理系统明确的指出该消息已经被处理完毕，从而确保你的数据被安全的保存直到你使用完毕。<br><strong>3.扩展性：</strong><br>　　因为消息队列解耦了你的处理过程，所以增大消息入队和处理的频率是很容易的，只要另外增加处理过程即可。<br><strong>4.灵活性 &amp; 峰值处理能力：</strong><br>　　在访问量剧增的情况下，应用仍然需要继续发挥作用，但是这样的突发流量并不常见。如果为以能处理这类峰值访问为标准来投入资源随时待命无疑是巨大的浪费。使用消息队列能够使关键组件顶住突发的访问压力，而不会因为突发的超负荷的请求而完全崩溃。<br><strong>5.可恢复性：</strong><br>　　系统的一部分组件失效时，不会影响到整个系统。消息队列降低了进程间的耦合度，所以即使一个处理消息的进程挂掉，加入队列中的消息仍然可以在系统恢复后被处理。<br><strong>6.顺序保证：</strong><br>　　在大多使用场景下，数据处理的顺序都很重要。大部分消息队列本来就是排序的，并且能保证数据会按照特定的顺序来处理。（Kafka 保证一个 Partition 内的消息的有序性）<br><strong>7.缓冲：</strong><br>　　有助于控制和优化数据流经过系统的速度，解决生产消息和消费消息的处理速度不一致的情况。<br><strong>8.异步通信：</strong><br>　　很多时候，用户不想也不需要立即处理消息。消息队列提供了异步处理机制，允许用户把一个消息放入队列，但并不立即处理它。想向队列中放入多少消息就放多少，然后在需要的时候再去处理它们。</p>
<h2 id="二、kafka-架构"><a href="#二、kafka-架构" class="headerlink" title="二、kafka 架构"></a><strong>二、kafka 架构</strong></h2><h3 id="2-1-拓扑结构"><a href="#2-1-拓扑结构" class="headerlink" title="2.1 拓扑结构"></a>2.1 拓扑结构</h3><p>如下图：</p>
<p><img src="https://raw.githubusercontent.com/Flyiyu/use/master/ka1.png" alt="image"></p>
<p>图.1</p>
<h3 id="2-2-相关概念"><a href="#2-2-相关概念" class="headerlink" title="2.2 相关概念"></a>2.2 相关概念</h3><ul>
<li><p><strong>Topic</strong>：Topic在逻辑上可以被认为是一个queue。每条消费都必须指定它的topic，可以简单理解为必须指明把这条消息放进哪个queue里。</p>
<ul>
<li>Partition:topic物理上的分区，一个topic可以分为多个partition，每个partition是一个有序的队列。</li>
<li>offset：每个partition都由一系列有序的、不可变的消息组成，这些消息被连续的追加到partition中。partition中的每个消息都有一个连续的序列号叫做offset,用于partition唯一标识一条消息.</li>
</ul>
</li>
<li><p><strong>Partition</strong>：是物理概念上的分区，为了提供系统吞吐率，在物理上每个Topic会分成一个或多个Partition，每个Partition对应一个文件夹，通过partition实现了并行处理和水平扩展</p>
<ul>
<li>Segment：<ul>
<li>partition物理上由多个segment组成，每个Segment存着message信息</li>
<li>一个Segment对应一个文件</li>
<li>Segment由一个个不可变记录组成</li>
<li>记录只会被append到Segment中，不会被单独修改或删除</li>
<li>清除过期日志时，直接删除一个或多个Segment</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>ISR</strong></p>
</li>
<li><p><strong>Producer</strong>：消息产生者，负责生产消息并发送到Kafka Broker</p>
</li>
<li><p><strong>Consumer</strong>：消息消费者，向kafka broker读取消息并处理的客户端。</p>
<ul>
<li><p>消费者就是消息的使用者，在消费者端也有几个名词需要区分一下。</p>
<blockquote>
<p>一般消息队列有两种模式的消费方式，分别是 队列模式 和 订阅模式。</p>
</blockquote>
<ul>
<li>队列模式：一对一，就是一个消息只能被一个消费者消费，不能重复消费。一般情况队列支持存在多个消费者，但是对于一个消息，只会有一个消费者可以消费它。</li>
<li>订阅模式：一对多，一个消息可能被多次消费，消息生产者将消息发布到Topic中，只要是订阅改Topic的消费者都可以消费。</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>Consumer Group</strong>：各个consumer（consumer 线程）可以组成一个组（Consumer group ），partition中的每个message只能被组（Consumer group ）中的一个consumer（consumer 线程）消费，如果一个message可以被多个consumer（consumer 线程）消费的话，那么这些consumer必须在不同的组。Kafka不支持一个partition中的message由两个或两个以上的同一个consumer group下的consumer thread来处理，除非再启动一个新的consumer group。所以如果想同时对一个topic做消费的话，启动多个consumer group就可以了，但是要注意的是，这里的多个consumer的消费都必须是顺序读取partition里面的message，新启动的consumer默认从partition队列最头端最新的地方开始阻塞的读message。</p>
</li>
<li><p><strong>Broker</strong>：消息中间件处理结点，一个Kafka节点就是一个broker，多个broker可以组成一个Kafka集群。</p>
<ul>
<li>Controller：中央控制器Control，负责管理分区和副本状态并执行管理着这些分区的重新分配。（里面涉及到partition leader 选举）</li>
<li>ISR：同步副本组</li>
</ul>
</li>
<li><p><strong>controller</strong>：kafka 集群中的其中一个服务器，用来进行 leader election 以及 各种 failover。</p>
</li>
<li><p><strong>删除</strong></p>
<ul>
<li>对于传统的message queue而言，一般会删除已经被消费的消息，而Kafka集群会保留所有的消息，无论其被消费与否。当然，因为磁盘限制，不可能永久保留所有数据（实际上也没必要），因此Kafka提供两种策略去删除旧数据。一是基于时间，二是基于partition文件大小。例如可以通过配置$KAFKA_HOME/config/server.properties，让Kafka删除一周前的数据，也可通过配置让Kafka在partition文件超过1GB时删除旧数据</li>
</ul>
</li>
</ul>
<h3 id="2-3-zookeeper-节点"><a href="#2-3-zookeeper-节点" class="headerlink" title="2.3 zookeeper 节点"></a>2.3 zookeeper 节点</h3><p>kafka 在 zookeeper 中的存储结构如下图所示：</p>
<p><img src="https://raw.githubusercontent.com/Flyiyu/use/master/ka2.png" alt="image"></p>
<p>图.2</p>
<h2 id="三、producer-发布消息"><a href="#三、producer-发布消息" class="headerlink" title="三、producer 发布消息"></a><strong>三、producer 发布消息</strong></h2><h3 id="3-1-写入方式"><a href="#3-1-写入方式" class="headerlink" title="3.1 写入方式"></a>3.1 写入方式</h3><p>producer 采用 push 模式将消息发布到 broker，每条消息都被 append 到 patition 中，属于顺序写磁盘（顺序写磁盘效率比随机写内存要高，保障 kafka 吞吐率）。</p>
<h3 id="3-2-消息路由"><a href="#3-2-消息路由" class="headerlink" title="3.2 消息路由"></a>3.2 消息路由</h3><p>producer 发送消息到 broker 时，会根据分区算法选择将其存储到哪一个 partition。其路由机制为：</p>
<p>1. 指定了 patition，则直接使用；<br>2. 未指定 patition 但指定 key，通过对 key 的 value 进行hash 选出一个 patition<br>3. patition 和 key 都未指定，使用轮询选出一个 patition。</p>
<p> 附上 java 客户端分区源码，一目了然：</p>
<pre><code>//创建消息实例  
public ProducerRecord(String topic, Integer partition, Long timestamp, K key, V value) {  
     if (topic == null)  
          throw new IllegalArgumentException("Topic cannot be null");  
     if (timestamp != null &amp;&amp; timestamp &lt; 0)  
          throw new IllegalArgumentException("Invalid timestamp " + timestamp);  
     this.topic = topic;  
     this.partition = partition;  
     this.key = key;  
     this.value = value;  
     this.timestamp = timestamp;  
}  

//计算 patition，如果指定了 patition 则直接使用，否则使用 key 计算  
private int partition(ProducerRecord&lt;K, V&gt; record, byte\[\] serializedKey , byte\[\] serializedValue, Cluster cluster) {  
     Integer partition = record.partition();  
     if (partition != null) {  
          List&lt;PartitionInfo&gt; partitions = cluster.partitionsForTopic(record.topic());  
          int lastPartition = partitions.size() - 1;  
          if (partition &lt; 0 || partition &gt; lastPartition) {  
               throw new IllegalArgumentException(String.format("Invalid partition given with record: %d is not in the range \[0...%d\].", partition, lastPartition));  
          }  
          return partition;  
     }  
     return this.partitioner.partition(record.topic(), record.key(), serializedKey, record.value(), serializedValue, cluster);  
}  

// 使用 key 选取 patition  
public int partition(String topic, Object key, byte\[\] keyBytes, Object value, byte\[\] valueBytes, Cluster cluster) {  
     List&lt;PartitionInfo&gt; partitions = cluster.partitionsForTopic(topic);  
     int numPartitions = partitions.size();  
     if (keyBytes == null) {  
          int nextValue = counter.getAndIncrement();  
          List&lt;PartitionInfo&gt; availablePartitions = cluster.availablePartitionsForTopic(topic);  
          if (availablePartitions.size() &gt; 0) {  
               int part = DefaultPartitioner.toPositive(nextValue) % availablePartitions.size();  
               return availablePartitions.get(part).partition();  
          } else {  
               return DefaultPartitioner.toPositive(nextValue) % numPartitions;  
          }  
     } else {  
          //对 keyBytes 进行 hash 选出一个 patition  
          return DefaultPartitioner.toPositive(Utils.murmur2(keyBytes)) % numPartitions;  
     }  
}
</code></pre><h3 id="3-3-写入流程"><a href="#3-3-写入流程" class="headerlink" title="3.3 写入流程"></a>3.3 写入流程</h3><p> producer 写入消息序列图如下所示：</p>
<p><img src="https://raw.githubusercontent.com/Flyiyu/use/master/ka3.png" alt="image"></p>
<p>图.3</p>
<p>流程说明：</p>
<p>1. producer 先从 zookeeper 的 “/brokers/…/state” 节点找到该 partition 的 leader<br>2. producer 将消息发送给该 leader<br>3. leader 将消息写入本地 log<br>4. followers 从 leader pull 消息，写入本地 log 后 leader 发送 ACK<br>5. leader 收到所有 ISR 中的 replica 的 ACK 后，增加 HW（high watermark，最后 commit 的 offset） 并向 producer 发送 ACK</p>
<h3 id="3-4-producer-delivery-guarantee"><a href="#3-4-producer-delivery-guarantee" class="headerlink" title="3.4 producer delivery guarantee"></a>3.4 producer delivery guarantee</h3><p> 一般情况下存在三种情况：</p>
<p>1. At most once 消息可能会丢，但绝不会重复传输<br>2. At least one 消息绝不会丢，但可能会重复传输<br>3. Exactly once 每条消息肯定会被传输一次且仅传输一次</p>
<p>当 producer 向 broker 发送消息时，一旦这条消息被 commit，由于 replication 的存在，它就不会丢。但是如果 producer 发送数据给 broker 后，遇到网络问题而造成通信中断，那 Producer 就无法判断该条消息是否已经 commit。虽然 Kafka 无法确定网络故障期间发生了什么，但是 producer 可以生成一种类似于主键的东西，发生故障时幂等性的重试多次，这样就做到了 Exactly once，但目前还并未实现。所以目前默认情况下一条消息从 producer 到 broker 是确保了 At least once，可通过设置 producer 异步发送实现At most once。</p>
<h2 id="四、broker-保存消息"><a href="#四、broker-保存消息" class="headerlink" title="四、broker 保存消息"></a><strong>四、broker 保存消息</strong></h2><h3 id="4-1-存储方式"><a href="#4-1-存储方式" class="headerlink" title="4.1 存储方式"></a>4.1 存储方式</h3><p>物理上把 topic 分成一个或多个 patition（对应 server.properties 中的 num.partitions=3 配置），每个 patition 物理上对应一个文件夹（该文件夹存储该 patition 的所有消息和索引文件），如下：</p>
<p><img src="https://raw.githubusercontent.com/Flyiyu/use/master/ka4.png" alt="image"></p>
<p>图.4</p>
<h3 id="4-2-存储策略"><a href="#4-2-存储策略" class="headerlink" title="4.2 存储策略"></a>4.2 存储策略</h3><p>无论消息是否被消费，kafka 都会保留所有消息。有两种策略可以删除旧数据：</p>
<p>1. 基于时间：log.retention.hours=168<br>2. 基于大小：log.retention.bytes=1073741824</p>
<p>需要注意的是，因为Kafka读取特定消息的时间复杂度为O(1)，即与文件大小无关，所以这里删除过期文件与提高 Kafka 性能无关。</p>
<h3 id="4-3-topic-创建与删除"><a href="#4-3-topic-创建与删除" class="headerlink" title="4.3 topic 创建与删除"></a>4.3 topic 创建与删除</h3><h4 id="4-3-1-创建-topic"><a href="#4-3-1-创建-topic" class="headerlink" title="4.3.1 创建 topic"></a>4.3.1 创建 topic</h4><p>创建 topic 的序列图如下所示：</p>
<p><img src="https://raw.githubusercontent.com/Flyiyu/use/master/ka5.png" alt="image"></p>
<p>图.5</p>
<p>流程说明：</p>
<p>1. controller 在 ZooKeeper 的 /brokers/topics 节点上注册 watcher，当 topic 被创建，则 controller 会通过 watch 得到该 topic 的 partition/replica 分配。<br>2. controller从 /brokers/ids 读取当前所有可用的 broker 列表，对于 set_p 中的每一个 partition：<br>    2.1 从分配给该 partition 的所有 replica（称为AR）中任选一个可用的 broker 作为新的 leader，并将AR设置为新的 ISR<br>    2.2 将新的 leader 和 ISR 写入 /brokers/topics/[topic]/partitions/[partition]/state<br>3. controller 通过 RPC 向相关的 broker 发送 LeaderAndISRRequest。</p>
<h4 id="4-3-2-删除-topic"><a href="#4-3-2-删除-topic" class="headerlink" title="4.3.2 删除 topic"></a>4.3.2 删除 topic</h4><p>删除 topic 的序列图如下所示：</p>
<p><img src="https://raw.githubusercontent.com/Flyiyu/use/master/ka6.png" alt="image"></p>
<p>图.6</p>
<p>流程说明：</p>
<p>1. controller 在 zooKeeper 的 /brokers/topics 节点上注册 watcher，当 topic 被删除，则 controller 会通过 watch 得到该 topic 的 partition/replica 分配。<br>2. 若 delete.topic.enable=false，结束；否则 controller 注册在 /admin/delete_topics 上的 watch 被 fire，controller 通过回调向对应的 broker 发送 StopReplicaRequest。</p>
<h2 id="五、kafka-HA"><a href="#五、kafka-HA" class="headerlink" title="五、kafka HA"></a><strong>五、kafka HA</strong></h2><h3 id="5-1-replication"><a href="#5-1-replication" class="headerlink" title="5.1 replication"></a>5.1 replication</h3><p>如图.1所示，同一个 partition 可能会有多个 replica（对应 server.properties 配置中的 default.replication.factor=N）。没有 replica 的情况下，一旦 broker 宕机，其上所有 patition 的数据都不可被消费，同时 producer 也不能再将数据存于其上的 patition。引入replication 之后，同一个 partition 可能会有多个 replica，而这时需要在这些 replica 之间选出一个 leader，producer 和 consumer 只与这个 leader 交互，其它 replica 作为 follower 从 leader 中复制数据。</p>
<p>Kafka 分配 Replica 的算法如下：</p>
<p>1. 将所有 broker（假设共 n 个 broker）和待分配的 partition 排序<br>2. 将第 i 个 partition 分配到第（i mod n）个 broker 上<br>3. 将第 i 个 partition 的第 j 个 replica 分配到第（(i + j) mode n）个 broker上</p>
<h3 id="5-2-leader-failover"><a href="#5-2-leader-failover" class="headerlink" title="5.2 leader failover"></a>5.2 leader failover</h3><p>当 partition 对应的 leader 宕机时，需要从 follower 中选举出新 leader。在选举新leader时，一个基本的原则是，新的 leader 必须拥有旧 leader commit 过的所有消息。</p>
<p>kafka 在 zookeeper 中（/brokers/…/state）动态维护了一个 ISR（in-sync replicas），由3.3节的写入流程可知 ISR 里面的所有 replica 都跟上了 leader，只有 ISR 里面的成员才能选为 leader。对于 f+1 个 replica，一个 partition 可以在容忍 f 个 replica 失效的情况下保证消息不丢失。</p>
<p>当所有 replica 都不工作时，有两种可行的方案：</p>
<p>1. 等待 ISR 中的任一个 replica 活过来，并选它作为 leader。可保障数据不丢失，但时间可能相对较长。<br>2. 选择第一个活过来的 replica（不一定是 ISR 成员）作为 leader。无法保障数据不丢失，但相对不可用时间较短。</p>
<p>kafka 0.8.* 使用第二种方式。</p>
<p>kafka 通过 Controller 来选举 leader，流程请参考5.3节。</p>
<h3 id="5-3-broker-failover"><a href="#5-3-broker-failover" class="headerlink" title="5.3 broker failover"></a>5.3 broker failover</h3><p>kafka broker failover 序列图如下所示：</p>
<p><img src="https://raw.githubusercontent.com/Flyiyu/use/master/ka7.png" alt="image"></p>
<p>图.7</p>
<p>流程说明： </p>
<p>1. controller 在 zookeeper 的 /brokers/ids/[brokerId] 节点注册 Watcher，当 broker 宕机时 zookeeper 会 fire watch<br>2. controller 从 /brokers/ids 节点读取可用broker<br>3. controller决定set_p，该集合包含宕机 broker 上的所有 partition<br>4. 对 set_p 中的每一个 partition<br>    4.1 从/brokers/topics/[topic]/partitions/[partition]/state 节点读取 ISR<br>    4.2 决定新 leader（如4.3节所描述）<br>    4.3 将新 leader、ISR、controller_epoch 和 leader_epoch 等信息写入 state 节点<br>5. 通过 RPC 向相关 broker 发送 leaderAndISRRequest 命令</p>
<h3 id="5-4-controller-failover"><a href="#5-4-controller-failover" class="headerlink" title="5.4 controller failover"></a>5.4 controller failover</h3><p> 当 controller 宕机时会触发 controller failover。每个 broker 都会在 zookeeper 的 “/controller” 节点注册 watcher，当 controller 宕机时 zookeeper 中的临时节点消失，所有存活的 broker 收到 fire 的通知，每个 broker 都尝试创建新的 controller path，只有一个竞选成功并当选为 controller。</p>
<p>当新的 controller 当选时，会触发 KafkaController.onControllerFailover 方法，在该方法中完成如下操作：</p>
<p>1. 读取并增加 Controller Epoch。<br>2. 在 reassignedPartitions Patch(/admin/reassign_partitions) 上注册 watcher。<br>3. 在 preferredReplicaElection Path(/admin/preferred_replica_election) 上注册 watcher。<br>4. 通过 partitionStateMachine 在 broker Topics Patch(/brokers/topics) 上注册 watcher。<br>5. 若 delete.topic.enable=true（默认值是 false），则 partitionStateMachine 在 Delete Topic Patch(/admin/delete_topics) 上注册 watcher。<br>6. 通过 replicaStateMachine在 Broker Ids Patch(/brokers/ids)上注册Watch。<br>7. 初始化 ControllerContext 对象，设置当前所有 topic，“活”着的 broker 列表，所有 partition 的 leader 及 ISR等。<br>8. 启动 replicaStateMachine 和 partitionStateMachine。<br>9. 将 brokerState 状态设置为 RunningAsController。<br>10. 将每个 partition 的 Leadership 信息发送给所有“活”着的 broker。<br>11. 若 auto.leader.rebalance.enable=true（默认值是true），则启动 partition-rebalance 线程。<br>12. 若 delete.topic.enable=true 且Delete Topic Patch(/admin/delete_topics)中有值，则删除相应的Topic。</p>
<h2 id="6-consumer-消费消息"><a href="#6-consumer-消费消息" class="headerlink" title="6. consumer 消费消息"></a><strong>6. consumer 消费消息</strong></h2><h3 id="6-1-consumer-API"><a href="#6-1-consumer-API" class="headerlink" title="6.1 consumer API"></a>6.1 consumer API</h3><p>kafka 提供了两套 consumer API：</p>
<p>1. The high-level Consumer API<br>2. The SimpleConsumer API</p>
<p> 其中 high-level consumer API 提供了一个从 kafka 消费数据的高层抽象，而 SimpleConsumer API 则需要开发人员更多地关注细节。</p>
<h4 id="6-1-1-The-high-level-consumer-API"><a href="#6-1-1-The-high-level-consumer-API" class="headerlink" title="6.1.1 The high-level consumer API"></a>6.1.1 The high-level consumer API</h4><p>high-level consumer API 提供了 consumer group 的语义，一个消息只能被 group 内的一个 consumer 所消费，且 consumer 消费消息时不关注 offset，最后一个 offset 由 zookeeper 保存。</p>
<p>使用 high-level consumer API 可以是多线程的应用，应当注意：</p>
<p>1. 如果消费线程大于 patition 数量，则有些线程将收不到消息<br>2. 如果 patition 数量大于线程数，则有些线程多收到多个 patition 的消息<br>3. 如果一个线程消费多个 patition，则无法保证你收到的消息的顺序，而一个 patition 内的消息是有序的</p>
<h4 id="6-1-2-The-SimpleConsumer-API"><a href="#6-1-2-The-SimpleConsumer-API" class="headerlink" title="6.1.2 The SimpleConsumer API"></a>6.1.2 The SimpleConsumer API</h4><p>如果你想要对 patition 有更多的控制权，那就应该使用 SimpleConsumer API，比如：</p>
<p>1. 多次读取一个消息<br>2. 只消费一个 patition 中的部分消息<br>3. 使用事务来保证一个消息仅被消费一次</p>
<p> 但是使用此 API 时，partition、offset、broker、leader 等对你不再透明，需要自己去管理。你需要做大量的额外工作：</p>
<p>1. 必须在应用程序中跟踪 offset，从而确定下一条应该消费哪条消息<br>2. 应用程序需要通过程序获知每个 Partition 的 leader 是谁<br>3. 需要处理 leader 的变更</p>
<p> 使用 SimpleConsumer API 的一般流程如下：</p>
<p>1. 查找到一个“活着”的 broker，并且找出每个 partition 的 leader<br>2. 找出每个 partition 的 follower<br>3. 定义好请求，该请求应该能描述应用程序需要哪些数据<br>4. fetch 数据<br>5. 识别 leader 的变化，并对之作出必要的响应</p>
<blockquote>
<p>以下针对 high-level Consumer API 进行说明。</p>
</blockquote>
<h3 id="6-2-consumer-group"><a href="#6-2-consumer-group" class="headerlink" title="6.2 consumer group"></a>6.2 consumer group</h3><p>如 2.2 节所说， kafka 的分配单位是 patition。每个 consumer 都属于一个 group，一个 partition 只能被同一个 group 内的一个 consumer 所消费（也就保障了一个消息只能被 group 内的一个 consuemr 所消费），但是多个 group 可以同时消费这个 partition。</p>
<p>kafka 的设计目标之一就是同时实现离线处理和实时处理，根据这一特性，可以使用 spark/Storm 这些实时处理系统对消息在线处理，同时使用 Hadoop 批处理系统进行离线处理，还可以将数据备份到另一个数据中心，只需要保证这三者属于不同的 consumer group。如下图所示：</p>
<p><img src="https://raw.githubusercontent.com/Flyiyu/use/master/ka9.jpg" alt="image"></p>
<h2 id="6-3-消费方式"><a href="#6-3-消费方式" class="headerlink" title="6.3 消费方式"></a><strong>6.3 消费方式</strong></h2><p>consumer 采用 pull 模式从 broker 中读取数据。</p>
<p>push 模式很难适应消费速率不同的消费者，因为消息发送速率是由 broker 决定的。它的目标是尽可能以最快速度传递消息，但是这样很容易造成 consumer 来不及处理消息，典型的表现就是拒绝服务以及网络拥塞。而 pull 模式则可以根据 consumer 的消费能力以适当的速率消费消息。</p>
<p>对于 Kafka 而言，pull 模式更合适，它可简化 broker 的设计，consumer 可自主控制消费消息的速率，同时 consumer 可以自己控制消费方式——即可批量消费也可逐条消费，同时还能选择不同的提交方式从而实现不同的传输语义。</p>
<h3 id="6-4-consumer-delivery-guarantee"><a href="#6-4-consumer-delivery-guarantee" class="headerlink" title="6.4 consumer delivery guarantee"></a>6.4 consumer delivery guarantee</h3><p>如果将 consumer 设置为 autocommit，consumer 一旦读到数据立即自动 commit。如果只讨论这一读取消息的过程，那 Kafka 确保了 Exactly once。</p>
<p>但实际使用中应用程序并非在 consumer 读取完数据就结束了，而是要进行进一步处理，而数据处理与 commit 的顺序在很大程度上决定了consumer delivery guarantee：</p>
<p><strong>1.读完消息先 commit 再处理消息。</strong><br>    这种模式下，如果 consumer 在 commit 后还没来得及处理消息就 crash 了，下次重新开始工作后就无法读到刚刚已提交而未处理的消息，这就对应于 At most once<br><strong>2.读完消息先处理再 commit。</strong><br>    这种模式下，如果在处理完消息之后 commit 之前 consumer crash 了，下次重新开始工作时还会处理刚刚未 commit 的消息，实际上该消息已经被处理过了。这就对应于 At least once。<br><strong>3.如果一定要做到 Exactly once，就需要协调 offset 和实际操作的输出。</strong><br>    精典的做法是引入两阶段提交。如果能让 offset 和操作输入存在同一个地方，会更简洁和通用。这种方式可能更好，因为许多输出系统可能不支持两阶段提交。比如，consumer 拿到数据后可能把数据放到 HDFS，如果把最新的 offset 和数据本身一起写到 HDFS，那就可以保证数据的输出和 offset 的更新要么都完成，要么都不完成，间接实现 Exactly once。（目前就 high-level API而言，offset 是存于Zookeeper 中的，无法存于HDFS，而SimpleConsuemr API的 offset 是由自己去维护的，可以将之存于 HDFS 中）</p>
<p>总之，Kafka 默认保证 At least once，并且允许通过设置 producer 异步提交来实现 At most once（见文章《kafka consumer防止数据丢失》）。而 Exactly once 要求与外部存储系统协作，幸运的是 kafka 提供的 offset 可以非常直接非常容易得使用这种方式。</p>
<p>更多关于 kafka 传输语义的信息请参考《Message Delivery Semantics》。</p>
<h3 id="6-5-consumer-rebalance"><a href="#6-5-consumer-rebalance" class="headerlink" title="6.5 consumer rebalance"></a>6.5 consumer rebalance</h3><p>当有 consumer 加入或退出、以及 partition 的改变（如 broker 加入或退出）时会触发 rebalance。consumer rebalance算法如下：</p>
<p>1. 将目标 topic 下的所有 partirtion 排序，存于PT<br>2. 对某 consumer group 下所有 consumer 排序，存于 CG，第 i 个consumer 记为 Ci<br>3. N=size(PT)/size(CG)，向上取整<br>4. 解除 Ci 对原来分配的 partition 的消费权（i从0开始）<br>5. 将第i*N到（i+1）*N-1个 partition 分配给 Ci</p>
<p>在 0.8.*版本，每个 consumer 都只负责调整自己所消费的 partition，为了保证整个consumer group 的一致性，当一个 consumer 触发了 rebalance 时，该 consumer group 内的其它所有其它 consumer 也应该同时触发 rebalance。这会导致以下几个问题：</p>
<p><strong>1.Herd effect</strong><br>　　任何 broker 或者 consumer 的增减都会触发所有的 consumer 的 rebalance<br><strong>2.Split Brain</strong><br>　　每个 consumer 分别单独通过 zookeeper 判断哪些 broker 和 consumer 宕机了，那么不同 consumer 在同一时刻从 zookeeper 看到的 view 就可能不一样，这是由 zookeeper 的特性决定的，这就会造成不正确的 reblance 尝试。<br><strong>3. 调整结果不可控</strong><br>　　所有的 consumer 都并不知道其它 consumer 的 rebalance 是否成功，这可能会导致 kafka 工作在一个不正确的状态。</p>
<p>基于以上问题，kafka 设计者考虑在0.9.*版本开始使用中心 coordinator 来控制 consumer rebalance，然后又从简便性和验证要求两方面考虑，计划在 consumer 客户端实现分配方案。（见文章《Kafka Detailed Consumer Coordinator Design》和《Kafka Client-side Assignment Proposal》），此处不再赘述。</p>
<h2 id="七、注意事项"><a href="#七、注意事项" class="headerlink" title="七、注意事项"></a><strong>七、注意事项</strong></h2><h3 id="7-1-producer-无法发送消息的问题"><a href="#7-1-producer-无法发送消息的问题" class="headerlink" title="7.1 producer 无法发送消息的问题"></a>7.1 producer 无法发送消息的问题</h3><p>最开始在本机搭建了kafka伪集群，本地 producer 客户端成功发布消息至 broker。随后在服务器上搭建了 kafka 集群，在本机连接该集群，producer 却无法发布消息到 broker（奇怪也没有抛错）。最开始怀疑是 iptables 没开放，于是开放端口，结果还不行（又开始是代码问题、版本问题等等，倒腾了很久）。最后没办法，一项一项查看 server.properties 配置，发现以下两个配置：</p>
<pre><code>\# The address the socket server listens on. It will get the value returned from   
\# java.net.InetAddress.getCanonicalHostName() if not configured.  
\#   FORMAT:  
\#     listeners = security\_protocol://host\_name:port  
\#   EXAMPLE:  
\#     listeners = PLAINTEXT://your.host.name:9092  
listeners=PLAINTEXT://:9092

　# Hostname and port the broker will advertise to producers and consumers. If not set,   
　# it uses the value for "listeners" if configured. Otherwise, it will use the value  
　# returned from java.net.InetAddress.getCanonicalHostName().  
　#advertised.listeners=PLAINTEXT://your.host.name:9092</code></pre><p>以上说的就是 advertised.listeners 是 broker 给 producer 和 consumer 连接使用的，如果没有设置，就使用 listeners，而如果 host_name 没有设置的话，就使用 java.net.InetAddress.getCanonicalHostName() 方法返回的主机名。</p>
<p>修改方法：</p>
<p>1. listeners=PLAINTEXT://121.10.26.XXX:9092<br>2. advertised.listeners=PLAINTEXT://121.10.26.XXX:9092</p>
<p>修改后重启服务，正常工作。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>
            </div>
            <hr/>

            

            <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">

<div id="article-share">
    
    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>


            


        </div>
    </div>

    
        <link rel="stylesheet" href="/libs/gitalk/gitalk.css">
<link rel="stylesheet" href="/css/my-gitalk.css">

<div class="card gitalk-card" data-aos="fade-up">
    <div id="gitalk-container" class="card-content"></div>
</div>

<script src="/libs/gitalk/gitalk.min.js"></script>
<script>
    let gitalk = new Gitalk({
        clientID: '33e35f8a39d17339ae45',
        clientSecret: 'c2daf8c102c345db91ff32aa45b2a692c7bdee25',
        repo: 'Fly_tom.github.io',
        owner: 'Flyiyu',
        admin: "Flyiyu",
        id: '2020-02-08T15-33-02',
        distractionFreeMode: false  // Facebook-like distraction free mode
    });

    gitalk.render('gitalk-container');
</script>
    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2020/02/08/2019-06-16-kafka-pei-zhi-xin-xi/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/13.jpg" class="responsive-img" alt="kafka配置信息">
                        
                        <span class="card-title">kafka配置信息</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            介绍
  Kafka是分布式发布-订阅消息系统，最初由LinkedIn公司开发，之后成为之后成为Apache基金会的一部分，由Scala和Java编写。Kafka是一种快速、可扩展的、设计内在就是分布式的，分区的和可复制的提交日志服务。


                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2020-02-08
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/kafka/" class="post-category">
                                    kafka
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/kafka/">
                        <span class="chip bg-color">kafka</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2020/02/08/2019-05-12-rabbitmq/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/10.jpg" class="responsive-img" alt="RabbitMQ笔记">
                        
                        <span class="card-title">RabbitMQ笔记</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            什么叫消息队列  消息（Message）是指在应用间传送的数据。消息可以非常简单，比如只包含文本字符串，也可以更复杂，可能包含嵌入对象。消息队列（Message Queue）是一种应用间的通信方式，消息发送后可以立即返回，由消息系统来确保消
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2020-02-08
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/RabbitMQ/" class="post-category">
                                    RabbitMQ
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/RabbitMQ/">
                        <span class="chip bg-color">RabbitMQ</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->

<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>


<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>

    
<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>
<script type="text/javascript" src="/libs/codeBlock/clipboard.min.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>


<!-- 代码块折行 -->

<style type="text/css">
code[class*="language-"], pre[class*="language-"] { white-space: pre !important; }
</style>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            // headingsOffset: -205,
            headingSelector: 'h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).slideUp(500);
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).slideDown(500);
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>



    <footer class="page-footer bg-color">
    <div class="container row center-align">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            <span id="year">年份 2019</span>
            <a href="https://flytom.club" target="_blank">FlyTom</a>
            <!-- |&nbsp;Powered by&nbsp;
            
            <a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
            &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                class="white-color">169.1k</span>&nbsp;字
             -->
            <!-- 
            
            
             -->
            <!-- 
            <!-- <span id="busuanzi_container_site_pv">
                |&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv"
                    class="white-color"></span>&nbsp;次
            </span> -->
            <!-- 
            
            <span id="busuanzi_container_site_uv">
                |&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv"
                    class="white-color"></span>&nbsp;人
            </span>
             -->
            <!-- <br> -->
            <!-- 
            <span id="sitetime">载入运行时间...</span>
            <script>
                function siteTime() {
                    window.setTimeout("siteTime()", 1000);
                    var seconds = 1000;
                    var minutes = seconds * 60;
                    var hours = minutes * 60;
                    var days = hours * 24;
                    var years = days * 365;
                    var today = new Date();
                    var startYear = "2019";
                    var startMonth = "6";
                    var startDate = "28";
                    var startHour = "0";
                    var startMinute = "0";
                    var startSecond = "0";
                    var todayYear = today.getFullYear();
                    var todayMonth = today.getMonth() + 1;
                    var todayDate = today.getDate();
                    var todayHour = today.getHours();
                    var todayMinute = today.getMinutes();
                    var todaySecond = today.getSeconds();
                    var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                    var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                    var diff = t2 - t1;
                    var diffYears = Math.floor(diff / years);
                    var diffDays = Math.floor((diff / days) - diffYears * 365);
                    var diffHours = Math.floor((diff - (diffYears * 365 + diffDays) * days) / hours);
                    var diffMinutes = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours) /
                        minutes);
                    var diffSeconds = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours -
                        diffMinutes * minutes) / seconds);
                    if (startYear == todayYear) {
                        document.getElementById("year").innerHTML = todayYear;
                        document.getElementById("sitetime").innerHTML = "本站已安全运行 " + diffDays + " 天 " + diffHours +
                            " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
                    } else {
                        document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                        document.getElementById("sitetime").innerHTML = "本站已安全运行 " + diffYears + " 年 " + diffDays +
                            " 天 " + diffHours + " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
                    }
                }
                setInterval(siteTime, 1000);
            </script>
             -->
            <!-- <br> -->
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis"><!-- 














    <a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50">
        <i class="fas fa-rss"></i>
    </a>
 -->
</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script src="/js/search.js"></script>
<script type="text/javascript">
$(function () {
    searchFunc("/" + "search.xml", 'searchInput', 'searchResult');
});
</script>
    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    <!-- Global site tag (gtag.js) - Google Analytics -->


    <!-- Baidu Analytics -->


    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    
    <script>
        (function (i, s, o, g, r, a, m) {
            i["DaoVoiceObject"] = r;
            i[r] = i[r] || function () {
                (i[r].q = i[r].q || []).push(arguments)
            }, i[r].l = 1 * new Date();
            a = s.createElement(o), m = s.getElementsByTagName(o)[0];
            a.async = 1;
            a.src = g;
            a.charset = "utf-8";
            m.parentNode.insertBefore(a, m)
        })(window, document, "script", ('https:' == document.location.protocol ? 'https:' : 'http:') +
            "//widget.daovoice.io/widget/6984b559.js", "daovoice")
        daovoice('init', {
            app_id: ""
        });
        daovoice('update');
    </script>
    

    

    

    
    
    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
